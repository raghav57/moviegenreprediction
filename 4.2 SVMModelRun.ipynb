{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all packages used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy as sp\n",
    "import string\n",
    "import en_core_web_sm\n",
    "import nltk as nl\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model = svm.SVC()\n",
    "param = {'kernel': ['linear','rbf']}\n",
    "\n",
    "lemm_obj = sp.load('en_core_web_lg')\n",
    "lemm_obj.max_length = 1500000\n",
    "ps = nl.PorterStemmer()\n",
    "\n",
    "vect_cnt = CountVectorizer(analyzer='word',min_df=1,stop_words='english',token_pattern='[a-zA-Z0-9]{1,}')\n",
    "tfidf_vect = TfidfVectorizer(analyzer = 'word', min_df = 1, stop_words = 'english',vocabulary=20000, token_pattern = '[a-zA-Z0-9]{1,}')\n",
    "\n",
    "allowed_postags = ['NOUN','ADJ','VERB','ADV']\n",
    "\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df_encode = pd.read_pickle(\"D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\gen_df_encode.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Animation',\n",
       " 'IMAX',\n",
       " 'Fantasy',\n",
       " 'Crime',\n",
       " 'Musical',\n",
       " 'Horror',\n",
       " 'Thriller',\n",
       " 'Sci-Fi',\n",
       " 'Film-Noir',\n",
       " 'Children',\n",
       " 'Mystery',\n",
       " 'War',\n",
       " 'Action',\n",
       " 'Drama',\n",
       " 'Western',\n",
       " 'Comedy',\n",
       " 'Romance',\n",
       " 'Documentary',\n",
       " 'Adventure']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullMovieData = pd.read_pickle(r\"D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\fullMovieData.pkl\")\n",
    "# List of genres\n",
    "g_list = fullMovieData.apply(lambda x: x['genres'].split('|'),axis = 1)\n",
    "g_list=g_list.to_list()\n",
    "g_list=list(set(sum(g_list,[])))\n",
    "g_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data=pd.DataFrame(columns=[\"Genre\",\"Actual Positives\",\"Actual Negatives\",\"Vectorizer\",\"Model\",\"Test_Precision\",\"Test_Recall\",\"Test_Fscore\",\"Precision\",\"Recall\",\"Fscore\"])\n",
    "Final_data.shape\n",
    "#Master function SVM RF Naive Bayes\n",
    "def prediction(df,text, genre, vectorizer, model, param):\n",
    "    result=[]\n",
    "    print(\"Genre for prediction: \", genre)\n",
    "    result.append(genre)\n",
    "    \n",
    "    #Sampling\n",
    "    df_model_0 = df[df[genre] == 0]\n",
    "    df_model_1 = df[df[genre] == 1]\n",
    "    print(\"Number of 0s: \", df_model_0.shape[0])\n",
    "    print(\"Number of 1s: \", df_model_1.shape[0])\n",
    "    result.append(df_model_0.shape[0])\n",
    "    result.append(df_model_1.shape[0]) \n",
    "    \n",
    "    sample_size = 2*df_model_1.shape[0]\n",
    "    if sample_size > len(df_model_0) : sample_size = len(df_model_0)\n",
    "    df_model_s=pd.concat([df_model_1,df_model_0.sample(sample_size)])\n",
    "    print(\"Shape of the Sampled DataFrame: \", df_model_s.shape)\n",
    "    #result.append(df_model_s.shape[0])\n",
    "    \n",
    "    #Train-Test Split\n",
    "    X_df = df_model_s[text]\n",
    "    y_df = df_model_s[genre]\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_df, y_df, test_size = 0.25, random_state = 1,\n",
    "                                                     shuffle = True)\n",
    "    \n",
    "    #Vectorization\n",
    "    print(\"\\n\")\n",
    "    print(\"Vectorization Start\")\n",
    "    vect = vectorizer(analyzer = 'word', min_df = 1, stop_words = 'english', token_pattern = '[a-zA-Z]{2,}')\n",
    "    vect_fit = vect.fit(X_train)\n",
    "    result.append(vectorizer)\n",
    "    \n",
    "    X_train_vec = pd.DataFrame(vect_fit.transform(X_train).toarray())\n",
    "    X_train_vec.columns = vect_fit.get_feature_names()\n",
    "    \n",
    "    X_test_vec = pd.DataFrame(vect_fit.transform(X_test).toarray())\n",
    "    X_test_vec.columns = vect_fit.get_feature_names()\n",
    "    print(\"Vectorization End\")\n",
    "    \n",
    "    #Model\n",
    "    print(\"\\n\")\n",
    "    print(\"Model Building Start\")\n",
    "    model = model\n",
    "    param = param\n",
    "    result.append(model)\n",
    "    \n",
    "    gs = GridSearchCV(model, param, cv = 5,n_jobs=2)\n",
    "    gs_fit = gs.fit(X_train_vec, y_train)\n",
    "    \n",
    "    test_pred_cnt = pd.DataFrame(gs.predict(X_test_vec))\n",
    "    train_pred_cnt = pd.DataFrame(gs.predict(X_train_vec))\n",
    "    print(\"Model Building End\")\n",
    "\n",
    "    # Accuracy metrics\n",
    "\n",
    "    #Test Accuracy\n",
    "    print(\"\\n\")\n",
    "    print(\"Sample data Test Set Confusion Matrix: \")\n",
    "    print(confusion_matrix(y_test, test_pred_cnt))\n",
    "    precision, recall, fscore, train_support = score(y_test, test_pred_cnt, pos_label = 1, average = 'binary')\n",
    "    print(\"Sample data Test Set Precision: \", precision)\n",
    "    print(\"Sample data Test Set Recall: \", recall)\n",
    "    print(\"Sample data Test Set FScore: \", fscore)\n",
    "    print(\"\\n\")\n",
    "    result.extend([precision, recall, fscore])\n",
    "\n",
    "    # Train Accuracy\n",
    "    print(\"Sample data Train Set Confusion Matrix: \")\n",
    "    print(confusion_matrix(y_train, train_pred_cnt))\n",
    "    precision, recall, fscore, train_support = score(y_train, train_pred_cnt, pos_label = 1, average = 'binary')\n",
    "    print(\"Sample data Train Set (Precision, Recall, Fscore) :\",precision, recall, fscore)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #Accuracy on full Data\n",
    "    X_df_full = df[text]\n",
    "    y_df_full = df[genre]\n",
    "\n",
    "    # vectorizer\n",
    "    X_full_tf = pd.DataFrame(vect_fit.transform(X_df_full).toarray())\n",
    "\n",
    "    print(\"Probability Evaluation and Concat Start\")\n",
    "    full_pred_cnt = pd.DataFrame(gs.predict(X_full_tf))\n",
    "    full_pred_prob = pd.DataFrame(gs.predict_proba(X_full_tf))\n",
    "    df = pd.concat([df,full_pred_prob], axis = 1)\n",
    "    df.rename(columns ={1:genre+'_prob'},inplace=True)\n",
    "    df.drop([0],axis=1,inplace=True)\n",
    "    print(\"Probability Evaluation and Concat End\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Full Dataset Confusion Matrix \" , model)\n",
    "    print(confusion_matrix(y_df_full, full_pred_cnt))\n",
    "    precision, recall, fscore, train_support = score(y_df_full, full_pred_cnt, pos_label = 1, average = 'binary')\n",
    "    print(\"Full Dataset Precision: \", precision)\n",
    "    print(\"Full Dataset Recall: \", recall)\n",
    "    print(\"Full Dataset FScore: \", fscore)\n",
    "    print(\"\\n\")\n",
    "    result.extend([precision, recall, fscore])\n",
    "    \n",
    "    print(\"Appending results to Final_data Start\")\n",
    "    Final_data.loc[len(Final_data)]=result\n",
    "    print(\"Appending results to Final_data End\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre for prediction:  Animation\n",
      "Number of 0s:  9998\n",
      "Number of 1s:  404\n",
      "Shape of the Sampled DataFrame:  (1212, 29)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[187  13]\n",
      " [ 43  60]]\n",
      "Sample data Test Set Precision:  0.821917808219178\n",
      "Sample data Test Set Recall:  0.5825242718446602\n",
      "Sample data Test Set FScore:  0.6818181818181818\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[607   1]\n",
      " [  3 298]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9966555183946488 0.9900332225913622 0.9933333333333334\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[9492  506]\n",
      " [  46  358]]\n",
      "Full Dataset Precision:  0.41435185185185186\n",
      "Full Dataset Recall:  0.8861386138613861\n",
      "Full Dataset FScore:  0.5646687697160883\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  IMAX\n",
      "Number of 0s:  10231\n",
      "Number of 1s:  171\n",
      "Shape of the Sampled DataFrame:  (513, 30)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[80 10]\n",
      " [19 20]]\n",
      "Sample data Test Set Precision:  0.6666666666666666\n",
      "Sample data Test Set Recall:  0.5128205128205128\n",
      "Sample data Test Set FScore:  0.5797101449275363\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[252   0]\n",
      " [  3 129]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9772727272727273 0.9885057471264368\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[9539  692]\n",
      " [  22  149]]\n",
      "Full Dataset Precision:  0.17717003567181927\n",
      "Full Dataset Recall:  0.8713450292397661\n",
      "Full Dataset FScore:  0.29446640316205536\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Fantasy\n",
      "Number of 0s:  9813\n",
      "Number of 1s:  589\n",
      "Shape of the Sampled DataFrame:  (1767, 31)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[285  21]\n",
      " [ 72  64]]\n",
      "Sample data Test Set Precision:  0.7529411764705882\n",
      "Sample data Test Set Recall:  0.47058823529411764\n",
      "Sample data Test Set FScore:  0.5791855203619909\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[871   1]\n",
      " [ 27 426]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9976580796252927 0.9403973509933775 0.9681818181818181\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[9306  507]\n",
      " [  99  490]]\n",
      "Full Dataset Precision:  0.49147442326980945\n",
      "Full Dataset Recall:  0.831918505942275\n",
      "Full Dataset FScore:  0.617906683480454\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Crime\n",
      "Number of 0s:  9176\n",
      "Number of 1s:  1226\n",
      "Shape of the Sampled DataFrame:  (3678, 32)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[543  53]\n",
      " [121 203]]\n",
      "Sample data Test Set Precision:  0.79296875\n",
      "Sample data Test Set Recall:  0.6265432098765432\n",
      "Sample data Test Set FScore:  0.7000000000000001\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[1834   22]\n",
      " [  51  851]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9747995418098511 0.9434589800443459 0.9588732394366197\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[8485  691]\n",
      " [ 172 1054]]\n",
      "Full Dataset Precision:  0.6040114613180516\n",
      "Full Dataset Recall:  0.8597063621533442\n",
      "Full Dataset FScore:  0.7095254123190845\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Musical\n",
      "Number of 0s:  10118\n",
      "Number of 1s:  284\n",
      "Shape of the Sampled DataFrame:  (852, 33)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[133   7]\n",
      " [ 37  36]]\n",
      "Sample data Test Set Precision:  0.8372093023255814\n",
      "Sample data Test Set Recall:  0.4931506849315068\n",
      "Sample data Test Set FScore:  0.6206896551724138\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[427   1]\n",
      " [  2 209]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9952380952380953 0.990521327014218 0.9928741092636579\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[9635  483]\n",
      " [  39  245]]\n",
      "Full Dataset Precision:  0.33653846153846156\n",
      "Full Dataset Recall:  0.8626760563380281\n",
      "Full Dataset FScore:  0.48418972332015814\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Horror\n",
      "Number of 0s:  9456\n",
      "Number of 1s:  946\n",
      "Shape of the Sampled DataFrame:  (2838, 34)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[444  32]\n",
      " [ 76 158]]\n",
      "Sample data Test Set Precision:  0.8315789473684211\n",
      "Sample data Test Set Recall:  0.6752136752136753\n",
      "Sample data Test Set FScore:  0.7452830188679246\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[1413    3]\n",
      " [  12  700]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9957325746799431 0.9831460674157303 0.9893992932862191\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[8896  560]\n",
      " [  88  858]]\n",
      "Full Dataset Precision:  0.6050775740479548\n",
      "Full Dataset Recall:  0.9069767441860465\n",
      "Full Dataset FScore:  0.7258883248730964\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Thriller\n",
      "Number of 0s:  8336\n",
      "Number of 1s:  2066\n",
      "Shape of the Sampled DataFrame:  (6198, 35)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[925 123]\n",
      " [202 300]]\n",
      "Sample data Test Set Precision:  0.7092198581560284\n",
      "Sample data Test Set Recall:  0.5976095617529881\n",
      "Sample data Test Set FScore:  0.6486486486486487\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[3030   54]\n",
      " [ 122 1442]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.963903743315508 0.921994884910486 0.9424836601307189\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[7628  708]\n",
      " [ 324 1742]]\n",
      "Full Dataset Precision:  0.7110204081632653\n",
      "Full Dataset Recall:  0.8431752178121975\n",
      "Full Dataset FScore:  0.7714791851195748\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Sci-Fi\n",
      "Number of 0s:  9754\n",
      "Number of 1s:  648\n",
      "Shape of the Sampled DataFrame:  (1944, 36)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[308  17]\n",
      " [ 60 101]]\n",
      "Sample data Test Set Precision:  0.8559322033898306\n",
      "Sample data Test Set Recall:  0.6273291925465838\n",
      "Sample data Test Set FScore:  0.7240143369175626\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[969   2]\n",
      " [  9 478]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9958333333333333 0.9815195071868583 0.9886246122026887\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[9355  399]\n",
      " [  69  579]]\n",
      "Full Dataset Precision:  0.5920245398773006\n",
      "Full Dataset Recall:  0.8935185185185185\n",
      "Full Dataset FScore:  0.7121771217712177\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Film-Noir\n",
      "Number of 0s:  10374\n",
      "Number of 1s:  28\n",
      "Shape of the Sampled DataFrame:  (84, 37)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[17  2]\n",
      " [ 2  0]]\n",
      "Sample data Test Set Precision:  0.0\n",
      "Sample data Test Set Recall:  0.0\n",
      "Sample data Test Set FScore:  0.0\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[37  0]\n",
      " [ 0 26]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 1.0 1.0\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[9582  792]\n",
      " [   2   26]]\n",
      "Full Dataset Precision:  0.03178484107579462\n",
      "Full Dataset Recall:  0.9285714285714286\n",
      "Full Dataset FScore:  0.061465721040189124\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Children\n",
      "Number of 0s:  9884\n",
      "Number of 1s:  518\n",
      "Shape of the Sampled DataFrame:  (1554, 38)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[256  13]\n",
      " [ 42  78]]\n",
      "Sample data Test Set Precision:  0.8571428571428571\n",
      "Sample data Test Set Recall:  0.65\n",
      "Sample data Test Set FScore:  0.7393364928909953\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[767   0]\n",
      " [  7 391]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9824120603015075 0.991128010139417\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[9286  598]\n",
      " [  49  469]]\n",
      "Full Dataset Precision:  0.4395501405810684\n",
      "Full Dataset Recall:  0.9054054054054054\n",
      "Full Dataset FScore:  0.5917981072555205\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Mystery\n",
      "Number of 0s:  9829\n",
      "Number of 1s:  573\n",
      "Shape of the Sampled DataFrame:  (1719, 39)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[263  27]\n",
      " [ 76  64]]\n",
      "Sample data Test Set Precision:  0.7032967032967034\n",
      "Sample data Test Set Recall:  0.45714285714285713\n",
      "Sample data Test Set FScore:  0.5541125541125541\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[854   2]\n",
      " [ 14 419]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.995249406175772 0.9676674364896074 0.9812646370023419\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[9010  819]\n",
      " [  90  483]]\n",
      "Full Dataset Precision:  0.3709677419354839\n",
      "Full Dataset Recall:  0.8429319371727748\n",
      "Full Dataset FScore:  0.5152000000000001\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  War\n",
      "Number of 0s:  10100\n",
      "Number of 1s:  302\n",
      "Shape of the Sampled DataFrame:  (906, 40)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[146   5]\n",
      " [ 24  52]]\n",
      "Sample data Test Set Precision:  0.9122807017543859\n",
      "Sample data Test Set Recall:  0.6842105263157895\n",
      "Sample data Test Set FScore:  0.7819548872180451\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[452   1]\n",
      " [  1 225]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.995575221238938 0.995575221238938 0.995575221238938\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[9715  385]\n",
      " [  25  277]]\n",
      "Full Dataset Precision:  0.41842900302114805\n",
      "Full Dataset Recall:  0.9172185430463576\n",
      "Full Dataset FScore:  0.5746887966804979\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Action\n",
      "Number of 0s:  8933\n",
      "Number of 1s:  1469\n",
      "Shape of the Sampled DataFrame:  (4407, 41)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[662  79]\n",
      " [103 258]]\n",
      "Sample data Test Set Precision:  0.7655786350148368\n",
      "Sample data Test Set Recall:  0.7146814404432132\n",
      "Sample data Test Set FScore:  0.7392550143266476\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[2170   27]\n",
      " [  52 1056]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9750692520775623 0.9530685920577617 0.9639434048379736\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[8236  697]\n",
      " [ 155 1314]]\n",
      "Full Dataset Precision:  0.6534062655395325\n",
      "Full Dataset Recall:  0.8944860449285228\n",
      "Full Dataset FScore:  0.7551724137931035\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Drama\n",
      "Number of 0s:  5155\n",
      "Number of 1s:  5247\n",
      "Shape of the Sampled DataFrame:  (10402, 42)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[906 359]\n",
      " [379 957]]\n",
      "Sample data Test Set Precision:  0.7272036474164134\n",
      "Sample data Test Set Recall:  0.7163173652694611\n",
      "Sample data Test Set FScore:  0.7217194570135747\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[3843   47]\n",
      " [  31 3880]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9880315762668704 0.9920736384556379 0.9900484817555499\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[4749  406]\n",
      " [ 410 4837]]\n",
      "Full Dataset Precision:  0.9225634178905207\n",
      "Full Dataset Recall:  0.9218601105393558\n",
      "Full Dataset FScore:  0.9222116301239275\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Western\n",
      "Number of 0s:  10305\n",
      "Number of 1s:  97\n",
      "Shape of the Sampled DataFrame:  (291, 43)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[51  1]\n",
      " [10 11]]\n",
      "Sample data Test Set Precision:  0.9166666666666666\n",
      "Sample data Test Set Recall:  0.5238095238095238\n",
      "Sample data Test Set FScore:  0.6666666666666667\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[142   0]\n",
      " [  0  76]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 1.0 1.0\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[9986  319]\n",
      " [  10   87]]\n",
      "Full Dataset Precision:  0.21428571428571427\n",
      "Full Dataset Recall:  0.8969072164948454\n",
      "Full Dataset FScore:  0.34592445328031807\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Comedy\n",
      "Number of 0s:  6914\n",
      "Number of 1s:  3488\n",
      "Shape of the Sampled DataFrame:  (10402, 44)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[1517  198]\n",
      " [ 408  478]]\n",
      "Sample data Test Set Precision:  0.7071005917159763\n",
      "Sample data Test Set Recall:  0.5395033860045146\n",
      "Sample data Test Set FScore:  0.6120358514724712\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[5116   83]\n",
      " [ 333 2269]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9647108843537415 0.872021521906226 0.916027452563585\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[6633  281]\n",
      " [ 741 2747]]\n",
      "Full Dataset Precision:  0.9071994715984147\n",
      "Full Dataset Recall:  0.7875573394495413\n",
      "Full Dataset FScore:  0.8431553100061387\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Romance\n",
      "Number of 0s:  8728\n",
      "Number of 1s:  1674\n",
      "Shape of the Sampled DataFrame:  (5022, 45)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[733  98]\n",
      " [212 213]]\n",
      "Sample data Test Set Precision:  0.684887459807074\n",
      "Sample data Test Set Recall:  0.5011764705882353\n",
      "Sample data Test Set FScore:  0.5788043478260869\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[2479   38]\n",
      " [ 125 1124]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9672977624784854 0.899919935948759 0.9323931978432185\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[8006  722]\n",
      " [ 337 1337]]\n",
      "Full Dataset Precision:  0.6493443419135503\n",
      "Full Dataset Recall:  0.7986857825567503\n",
      "Full Dataset FScore:  0.7163139566032681\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Documentary\n",
      "Number of 0s:  9342\n",
      "Number of 1s:  1060\n",
      "Shape of the Sampled DataFrame:  (3180, 46)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[496  22]\n",
      " [ 54 223]]\n",
      "Sample data Test Set Precision:  0.9102040816326531\n",
      "Sample data Test Set Recall:  0.8050541516245487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data Test Set FScore:  0.8544061302681991\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[1594    8]\n",
      " [  11  772]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9897435897435898 0.9859514687100894 0.9878438899552143\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[8986  356]\n",
      " [  65  995]]\n",
      "Full Dataset Precision:  0.7364914877868246\n",
      "Full Dataset Recall:  0.9386792452830188\n",
      "Full Dataset FScore:  0.8253836582330982\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Adventure\n",
      "Number of 0s:  9516\n",
      "Number of 1s:  886\n",
      "Shape of the Sampled DataFrame:  (2658, 47)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[403  43]\n",
      " [ 85 134]]\n",
      "Sample data Test Set Precision:  0.7570621468926554\n",
      "Sample data Test Set Recall:  0.6118721461187214\n",
      "Sample data Test Set FScore:  0.6767676767676768\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[1321    5]\n",
      " [  20  647]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9923312883435583 0.9700149925037481 0.9810462471569371\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  SVC(probability=True)\n",
      "[[8765  751]\n",
      " [ 105  781]]\n",
      "Full Dataset Precision:  0.5097911227154047\n",
      "Full Dataset Recall:  0.881489841986456\n",
      "Full Dataset FScore:  0.6459884201819686\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e549a2a1cd26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'plot_lemm'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;33m{\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\SVM_Probability_Distribution_plots.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mResult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\Result_SVM.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Result' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_test=gen_df_encode\n",
    "for i in g_list:    \n",
    "    df_test = prediction(df_test,'plot_lemm',i,TfidfVectorizer, svm.SVC(probability=True),  {'kernel': ['linear','rbf']})\n",
    "df_test.to_pickle(r'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\SVM_Probability_Distribution_plots.pkl')\n",
    "Result.to_pickle(r'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\Result_SVM.pkl')\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "\n",
    "print(\"Total Time taken:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "df_test=gen_df_encode\n",
    "for i in g_list:    \n",
    "    df_test = prediction(df_test,'plot_tt',i,TfidfVectorizer, svm.SVC(probability=True),  {'kernel': ['linear','rbf']})\n",
    "df_test.to_pickle(r'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\SVM_Probability_Distribution_tt.pkl')\n",
    "Result.to_pickle(r'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\Result_SVM.pkl')\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "\n",
    "print(\"Total Time taken:\" + str(end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
