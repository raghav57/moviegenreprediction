{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all packages used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy as sp\n",
    "import string\n",
    "import en_core_web_sm\n",
    "import nltk as nl\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model = svm.SVC()\n",
    "param = {'kernel': ['linear','rbf']}\n",
    "\n",
    "lemm_obj = sp.load('en_core_web_lg')\n",
    "lemm_obj.max_length = 1500000\n",
    "ps = nl.PorterStemmer()\n",
    "\n",
    "vect_cnt = CountVectorizer(analyzer='word',min_df=1,stop_words='english',token_pattern='[a-zA-Z0-9]{1,}')\n",
    "tfidf_vect = TfidfVectorizer(analyzer = 'word', min_df = 1, stop_words = 'english',vocabulary=20000, token_pattern = '[a-zA-Z0-9]{1,}')\n",
    "\n",
    "allowed_postags = ['NOUN','ADJ','VERB','ADV']\n",
    "\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23112 entries, 0 to 25434\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   youtubeId          23112 non-null  object\n",
      " 1   movieId            23112 non-null  int64 \n",
      " 2   title              23112 non-null  object\n",
      " 3   trailerTranscript  23112 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 902.8+ KB\n"
     ]
    }
   ],
   "source": [
    "trailerData = pd.read_pickle(r\"D:\\Machine Learning\\Vamsi Thesis\\Code\\trailerTranscripts.pkl\")\n",
    "trailerData = trailerData[trailerData['trailerTranscript']!='']\n",
    "trailerData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42457 entries, 0 to 62421\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   movieId  42457 non-null  int64  \n",
      " 1   imdbId   42457 non-null  int64  \n",
      " 2   tmdbId   42362 non-null  float64\n",
      " 3   plot     42457 non-null  object \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "movieId = pd.read_pickle(r\"D:\\Machine Learning\\Vamsi Thesis\\Code\\moviePlots.pkl\")\n",
    "plotData = movieId[movieId['plot']!='']\n",
    "plotData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12844 entries, 0 to 12843\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   movieId            12844 non-null  int64 \n",
      " 1   title              12844 non-null  object\n",
      " 2   trailerTranscript  12844 non-null  object\n",
      " 3   plot               12844 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 501.7+ KB\n"
     ]
    }
   ],
   "source": [
    "plotTrailer = trailerData[['movieId','title','trailerTranscript']].merge(plotData[['movieId','plot']], on='movieId',how='inner')\n",
    "plotTrailer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62423 entries, 0 to 62422\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  62423 non-null  int64 \n",
      " 1   genres   62423 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 975.5+ KB\n"
     ]
    }
   ],
   "source": [
    "genreData = pd.read_csv(r\"D:\\Machine Learning\\Vamsi Thesis\\Data\\ml-25m\\movies.csv\",usecols=[\"movieId\",\"genres\"])\n",
    "genreData.info()\n",
    "fullMovieData = plotTrailer.merge(genreData,on='movieId',how='inner')\n",
    "fullMovieData\n",
    "# Removing dummy plots\n",
    "test = fullMovieData[fullMovieData['movieId']==71]\n",
    "plot = (test.loc[:,'plot']).tolist()\n",
    "fullMovieData =  fullMovieData[fullMovieData['plot']!=plot[0]]\n",
    "fullMovieData = fullMovieData[fullMovieData['genres']!='(no genres listed)']\n",
    "fullMovieData['ttLength']=fullMovieData.apply(lambda x: len(x['trailerTranscript']),axis=1)\n",
    "fullMovieData=fullMovieData[fullMovieData['ttLength']<=10000]\n",
    "fullMovieData=fullMovieData[fullMovieData['ttLength']>=100]\n",
    "fullMovieData.describe(percentiles=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.99,1])\n",
    "fullMovieData\n",
    "fullMovieData.reset_index(inplace=True)\n",
    "fullMovieData.to_pickle(r'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\fullMovieData.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adventure',\n",
       " 'Romance',\n",
       " 'Horror',\n",
       " 'Comedy',\n",
       " 'Mystery',\n",
       " 'Action',\n",
       " 'Film-Noir',\n",
       " 'Thriller',\n",
       " 'Drama',\n",
       " 'IMAX',\n",
       " 'Fantasy',\n",
       " 'War',\n",
       " 'Animation',\n",
       " 'Crime',\n",
       " 'Western',\n",
       " 'Sci-Fi',\n",
       " 'Musical',\n",
       " 'Children',\n",
       " 'Documentary']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of genres\n",
    "g_list = fullMovieData.apply(lambda x: x['genres'].split('|'),axis = 1)\n",
    "g_list=g_list.to_list()\n",
    "g_list=list(set(sum(g_list,[])))\n",
    "g_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>trailerTranscript</th>\n",
       "      <th>plot</th>\n",
       "      <th>genres</th>\n",
       "      <th>ttLength</th>\n",
       "      <th>movieId</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Romance</th>\n",
       "      <th>...</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>War</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Western</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Children</th>\n",
       "      <th>Documentary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>sergeant yes sir establish a recon post downst...</td>\n",
       "      <td>A little boy named Andy loves to be in his roo...</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>It's gotta be micro-chipped or something You g...</td>\n",
       "      <td>Jumanji, one of the most unique--and dangerous...</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>or on hot crankier my dog was as ugly as you l...</td>\n",
       "      <td>Things don't seem to change much in Wabasha Co...</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>[Music] savannah bernadine robin gloria [Music...</td>\n",
       "      <td>This story based on the best selling novel by ...</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>[Music] we're George banks life was good it wa...</td>\n",
       "      <td>In this sequel to \"Father of the Bride\", Georg...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>12839</td>\n",
       "      <td>124273</td>\n",
       "      <td>Kevin Smith: Too Fat For 40 (2010)</td>\n",
       "      <td>I was just wondering,\\nin all the Cousin Walte...</td>\n",
       "      <td>A no holds barred concert with award winning f...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>8300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>12840</td>\n",
       "      <td>125429</td>\n",
       "      <td>Johnny Skidmarks (1998)</td>\n",
       "      <td>[Music] [Applause] [Music] [Applause] [Music] ...</td>\n",
       "      <td>Crime scene photographer, Johnny Scardino (aka...</td>\n",
       "      <td>Crime|Drama|Mystery|Thriller</td>\n",
       "      <td>3113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>12841</td>\n",
       "      <td>127272</td>\n",
       "      <td>Nobody Knows Anything! (2003)</td>\n",
       "      <td>I came into this business when I was at Prince...</td>\n",
       "      <td>In this comedy about Hollywood, Sarah thinks m...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>12842</td>\n",
       "      <td>128439</td>\n",
       "      <td>Point and Shoot (2014)</td>\n",
       "      <td>I was raised on action movies all my adventure...</td>\n",
       "      <td>Matthew VanDyke presents slices of his life fr...</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>1547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>12843</td>\n",
       "      <td>130077</td>\n",
       "      <td>Lost for Life (2013)</td>\n",
       "      <td>there should be no odds against killing people...</td>\n",
       "      <td>In the United States today, more than 2,500 in...</td>\n",
       "      <td>Crime|Documentary</td>\n",
       "      <td>641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10402 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  movieId                               title  \\\n",
       "0          0        1                    Toy Story (1995)   \n",
       "1          1        2                      Jumanji (1995)   \n",
       "2          2        3             Grumpier Old Men (1995)   \n",
       "3          3        4            Waiting to Exhale (1995)   \n",
       "4          4        5  Father of the Bride Part II (1995)   \n",
       "...      ...      ...                                 ...   \n",
       "10397  12839   124273  Kevin Smith: Too Fat For 40 (2010)   \n",
       "10398  12840   125429             Johnny Skidmarks (1998)   \n",
       "10399  12841   127272       Nobody Knows Anything! (2003)   \n",
       "10400  12842   128439              Point and Shoot (2014)   \n",
       "10401  12843   130077                Lost for Life (2013)   \n",
       "\n",
       "                                       trailerTranscript  \\\n",
       "0      sergeant yes sir establish a recon post downst...   \n",
       "1      It's gotta be micro-chipped or something You g...   \n",
       "2      or on hot crankier my dog was as ugly as you l...   \n",
       "3      [Music] savannah bernadine robin gloria [Music...   \n",
       "4      [Music] we're George banks life was good it wa...   \n",
       "...                                                  ...   \n",
       "10397  I was just wondering,\\nin all the Cousin Walte...   \n",
       "10398  [Music] [Applause] [Music] [Applause] [Music] ...   \n",
       "10399  I came into this business when I was at Prince...   \n",
       "10400  I was raised on action movies all my adventure...   \n",
       "10401  there should be no odds against killing people...   \n",
       "\n",
       "                                                    plot  \\\n",
       "0      A little boy named Andy loves to be in his roo...   \n",
       "1      Jumanji, one of the most unique--and dangerous...   \n",
       "2      Things don't seem to change much in Wabasha Co...   \n",
       "3      This story based on the best selling novel by ...   \n",
       "4      In this sequel to \"Father of the Bride\", Georg...   \n",
       "...                                                  ...   \n",
       "10397  A no holds barred concert with award winning f...   \n",
       "10398  Crime scene photographer, Johnny Scardino (aka...   \n",
       "10399  In this comedy about Hollywood, Sarah thinks m...   \n",
       "10400  Matthew VanDyke presents slices of his life fr...   \n",
       "10401  In the United States today, more than 2,500 in...   \n",
       "\n",
       "                                            genres  ttLength  movieId  \\\n",
       "0      Adventure|Animation|Children|Comedy|Fantasy       676      0.0   \n",
       "1                       Adventure|Children|Fantasy       249      0.0   \n",
       "2                                   Comedy|Romance      1053      0.0   \n",
       "3                             Comedy|Drama|Romance      1740      0.0   \n",
       "4                                           Comedy      1499      0.0   \n",
       "...                                            ...       ...      ...   \n",
       "10397                                       Comedy      8300      0.0   \n",
       "10398                 Crime|Drama|Mystery|Thriller      3113      0.0   \n",
       "10399                                       Comedy       636      0.0   \n",
       "10400                                  Documentary      1547      0.0   \n",
       "10401                            Crime|Documentary       641      0.0   \n",
       "\n",
       "       Adventure  Romance  ...  IMAX  Fantasy  War  Animation  Crime  Western  \\\n",
       "0            0.0      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0   \n",
       "1            0.0      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0   \n",
       "2            0.0      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0   \n",
       "3            0.0      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0   \n",
       "4            0.0      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0   \n",
       "...          ...      ...  ...   ...      ...  ...        ...    ...      ...   \n",
       "10397        0.0      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0   \n",
       "10398        0.0      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0   \n",
       "10399        0.0      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0   \n",
       "10400        0.0      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0   \n",
       "10401        0.0      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0   \n",
       "\n",
       "       Sci-Fi  Musical  Children  Documentary  \n",
       "0         0.0      0.0       0.0          0.0  \n",
       "1         0.0      0.0       0.0          0.0  \n",
       "2         0.0      0.0       0.0          0.0  \n",
       "3         0.0      0.0       0.0          0.0  \n",
       "4         0.0      0.0       0.0          0.0  \n",
       "...       ...      ...       ...          ...  \n",
       "10397     0.0      0.0       0.0          0.0  \n",
       "10398     0.0      0.0       0.0          0.0  \n",
       "10399     0.0      0.0       0.0          0.0  \n",
       "10400     0.0      0.0       0.0          0.0  \n",
       "10401     0.0      0.0       0.0          0.0  \n",
       "\n",
       "[10402 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Genre one hot encoding\n",
    "data = np.zeros(shape=(len(fullMovieData),len(g_list)+1))\n",
    "gen_df_encode = pd.DataFrame(data,columns=['movieId']+g_list)\n",
    "gen_df_encode = pd.concat([fullMovieData,gen_df_encode],axis=1)\n",
    "gen_df_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10402, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>trailerTranscript</th>\n",
       "      <th>plot</th>\n",
       "      <th>genres</th>\n",
       "      <th>ttLength</th>\n",
       "      <th>movieId</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Romance</th>\n",
       "      <th>...</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>War</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Western</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Children</th>\n",
       "      <th>Documentary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>sergeant yes sir establish a recon post downst...</td>\n",
       "      <td>A little boy named Andy loves to be in his roo...</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>It's gotta be micro-chipped or something You g...</td>\n",
       "      <td>Jumanji, one of the most unique--and dangerous...</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>or on hot crankier my dog was as ugly as you l...</td>\n",
       "      <td>Things don't seem to change much in Wabasha Co...</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>[Music] savannah bernadine robin gloria [Music...</td>\n",
       "      <td>This story based on the best selling novel by ...</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>[Music] we're George banks life was good it wa...</td>\n",
       "      <td>In this sequel to \"Father of the Bride\", Georg...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  movieId                               title  \\\n",
       "0      0        1                    Toy Story (1995)   \n",
       "1      1        2                      Jumanji (1995)   \n",
       "2      2        3             Grumpier Old Men (1995)   \n",
       "3      3        4            Waiting to Exhale (1995)   \n",
       "4      4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                   trailerTranscript  \\\n",
       "0  sergeant yes sir establish a recon post downst...   \n",
       "1  It's gotta be micro-chipped or something You g...   \n",
       "2  or on hot crankier my dog was as ugly as you l...   \n",
       "3  [Music] savannah bernadine robin gloria [Music...   \n",
       "4  [Music] we're George banks life was good it wa...   \n",
       "\n",
       "                                                plot  \\\n",
       "0  A little boy named Andy loves to be in his roo...   \n",
       "1  Jumanji, one of the most unique--and dangerous...   \n",
       "2  Things don't seem to change much in Wabasha Co...   \n",
       "3  This story based on the best selling novel by ...   \n",
       "4  In this sequel to \"Father of the Bride\", Georg...   \n",
       "\n",
       "                                        genres  ttLength  movieId  Adventure  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy       676      0.0        1.0   \n",
       "1                   Adventure|Children|Fantasy       249      0.0        1.0   \n",
       "2                               Comedy|Romance      1053      0.0        0.0   \n",
       "3                         Comedy|Drama|Romance      1740      0.0        0.0   \n",
       "4                                       Comedy      1499      0.0        0.0   \n",
       "\n",
       "   Romance  ...  IMAX  Fantasy  War  Animation  Crime  Western  Sci-Fi  \\\n",
       "0      0.0  ...   0.0      1.0  0.0        1.0    0.0      0.0     0.0   \n",
       "1      0.0  ...   0.0      1.0  0.0        0.0    0.0      0.0     0.0   \n",
       "2      1.0  ...   0.0      0.0  0.0        0.0    0.0      0.0     0.0   \n",
       "3      1.0  ...   0.0      0.0  0.0        0.0    0.0      0.0     0.0   \n",
       "4      0.0  ...   0.0      0.0  0.0        0.0    0.0      0.0     0.0   \n",
       "\n",
       "   Musical  Children  Documentary  \n",
       "0      0.0       1.0          0.0  \n",
       "1      0.0       1.0          0.0  \n",
       "2      0.0       0.0          0.0  \n",
       "3      0.0       0.0          0.0  \n",
       "4      0.0       0.0          0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def genre_one_hot_encoding(df):\n",
    "    for i in range(0, len(df)):\n",
    "        genres = str(df.loc[i, 'genres'])\n",
    "        genres = genres.strip()\n",
    "        genres = genres.split('|')\n",
    "        #print(genres)\n",
    "        for g in genres:\n",
    "            df.loc[i,g] = int(1)\n",
    "    return df\n",
    "gen_df_encode = genre_one_hot_encoding(gen_df_encode)\n",
    "print(gen_df_encode.shape)\n",
    "gen_df_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Processing\n",
    "def stemming(text):\n",
    "    text = ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('[^a-zA-Z]*', text)\n",
    "    text = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(text)\n",
    "def Lemm(text):\n",
    "    texts_out = []\n",
    "    text = ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    doc = lemm_obj(text)\n",
    "    x=' '.join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc])\n",
    "    return re.sub(' +',' ',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken:513.5435507297516\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "# gen_df_encode['tt_stemmed'] = gen_df_encode.apply(lambda x: stemming(x['trailerTranscript']),axis = 1)\n",
    "gen_df_encode['tt_lemm'] = gen_df_encode.apply(lambda x: Lemm(x['trailerTranscript']),axis = 1)\n",
    "# gen_df_encode['plot_stemmed'] = gen_df_encode.apply(lambda x: stemming(x['plot']),axis = 1)\n",
    "gen_df_encode['plot_lemm'] = gen_df_encode.apply(lambda x: Lemm(x['plot']),axis = 1)\n",
    "gen_df_encode\n",
    "\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "\n",
    "print(\"Total Time taken:\" + str(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df_encode.to_pickle(r'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\gen_df_encode.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data=pd.DataFrame(columns=[\"Genre\",\"Actual Positives\",\"Actual Negatives\",\"Vectorizer\",\"Model\",\"Test_Precision\",\"Test_Recall\",\"Test_Fscore\",\"Precision\",\"Recall\",\"Fscore\"])\n",
    "Final_data.shape\n",
    "#Master function SVM RF Naive Bayes\n",
    "def prediction(df,text, genre, vectorizer, model, param):\n",
    "    result=[]\n",
    "    print(\"Genre for prediction: \", genre)\n",
    "    result.append(genre)\n",
    "    \n",
    "    #Sampling\n",
    "    df_model_0 = df[df[genre] == 0]\n",
    "    df_model_1 = df[df[genre] == 1]\n",
    "    print(\"Number of 0s: \", df_model_0.shape[0])\n",
    "    print(\"Number of 1s: \", df_model_1.shape[0])\n",
    "    result.append(df_model_0.shape[0])\n",
    "    result.append(df_model_1.shape[0]) \n",
    "    \n",
    "    sample_size = 2*df_model_1.shape[0]\n",
    "    if sample_size > len(df_model_0) : sample_size = len(df_model_0)\n",
    "    df_model_s=pd.concat([df_model_1,df_model_0.sample(sample_size)])\n",
    "    print(\"Shape of the Sampled DataFrame: \", df_model_s.shape)\n",
    "    #result.append(df_model_s.shape[0])\n",
    "    \n",
    "    #Train-Test Split\n",
    "    X_df = df_model_s[text]\n",
    "    y_df = df_model_s[genre]\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_df, y_df, test_size = 0.25, random_state = 1,\n",
    "                                                     shuffle = True)\n",
    "    \n",
    "    #Vectorization\n",
    "    print(\"\\n\")\n",
    "    print(\"Vectorization Start\")\n",
    "    vect = vectorizer(analyzer = 'word', min_df = 1, stop_words = 'english', token_pattern = '[a-zA-Z]{2,}')\n",
    "    vect_fit = vect.fit(X_train)\n",
    "    result.append(vectorizer)\n",
    "    \n",
    "    X_train_vec = pd.DataFrame(vect_fit.transform(X_train).toarray())\n",
    "    X_train_vec.columns = vect_fit.get_feature_names()\n",
    "    \n",
    "    X_test_vec = pd.DataFrame(vect_fit.transform(X_test).toarray())\n",
    "    X_test_vec.columns = vect_fit.get_feature_names()\n",
    "    print(\"Vectorization End\")\n",
    "    \n",
    "    #Model\n",
    "    print(\"\\n\")\n",
    "    print(\"Model Building Start\")\n",
    "    model = model\n",
    "    param = param\n",
    "    result.append(model)\n",
    "    \n",
    "    gs = GridSearchCV(model, param, cv = 5,n_jobs=2)\n",
    "    gs_fit = gs.fit(X_train_vec, y_train)\n",
    "    \n",
    "    test_pred_cnt = pd.DataFrame(gs.predict(X_test_vec))\n",
    "    train_pred_cnt = pd.DataFrame(gs.predict(X_train_vec))\n",
    "    print(\"Model Building End\")\n",
    "\n",
    "    # Accuracy metrics\n",
    "\n",
    "    #Test Accuracy\n",
    "    print(\"\\n\")\n",
    "    print(\"Sample data Test Set Confusion Matrix: \")\n",
    "    print(confusion_matrix(y_test, test_pred_cnt))\n",
    "    precision, recall, fscore, train_support = score(y_test, test_pred_cnt, pos_label = 1, average = 'binary')\n",
    "    print(\"Sample data Test Set Precision: \", precision)\n",
    "    print(\"Sample data Test Set Recall: \", recall)\n",
    "    print(\"Sample data Test Set FScore: \", fscore)\n",
    "    print(\"\\n\")\n",
    "    result.extend([precision, recall, fscore])\n",
    "\n",
    "    # Train Accuracy\n",
    "    print(\"Sample data Train Set Confusion Matrix: \")\n",
    "    print(confusion_matrix(y_train, train_pred_cnt))\n",
    "    precision, recall, fscore, train_support = score(y_train, train_pred_cnt, pos_label = 1, average = 'binary')\n",
    "    print(\"Sample data Train Set (Precision, Recall, Fscore) :\",precision, recall, fscore)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #Accuracy on full Data\n",
    "    X_df_full = df[text]\n",
    "    y_df_full = df[genre]\n",
    "\n",
    "    # vectorizer\n",
    "    X_full_tf = pd.DataFrame(vect_fit.transform(X_df_full).toarray())\n",
    "\n",
    "    print(\"Probability Evaluation and Concat Start\")\n",
    "    full_pred_cnt = pd.DataFrame(gs.predict(X_full_tf))\n",
    "    full_pred_prob = pd.DataFrame(gs.predict_proba(X_full_tf))\n",
    "    df = pd.concat([df,full_pred_prob], axis = 1)\n",
    "    df.rename(columns ={1:genre+'_prob'},inplace=True)\n",
    "    df.drop([0],axis=1,inplace=True)\n",
    "    print(\"Probability Evaluation and Concat End\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Full Dataset Confusion Matrix \" , model)\n",
    "    print(confusion_matrix(y_df_full, full_pred_cnt))\n",
    "    precision, recall, fscore, train_support = score(y_df_full, full_pred_cnt, pos_label = 1, average = 'binary')\n",
    "    print(\"Full Dataset Precision: \", precision)\n",
    "    print(\"Full Dataset Recall: \", recall)\n",
    "    print(\"Full Dataset FScore: \", fscore)\n",
    "    print(\"\\n\")\n",
    "    result.extend([precision, recall, fscore])\n",
    "    \n",
    "    print(\"Appending results to Final_data Start\")\n",
    "    Final_data.loc[len(Final_data)]=result\n",
    "    print(\"Appending results to Final_data End\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre for prediction:  Comedy\n",
      "Number of 0s:  6914\n",
      "Number of 1s:  3488\n",
      "Shape of the Sampled DataFrame:  (10402, 29)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[1683   32]\n",
      " [ 751  135]]\n",
      "Sample data Test Set Precision:  0.8083832335329342\n",
      "Sample data Test Set Recall:  0.1523702031602709\n",
      "Sample data Test Set FScore:  0.25641025641025644\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[5199    0]\n",
      " [ 201 2401]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9227517294388932 0.959824105536678\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[6882   32]\n",
      " [ 952 2536]]\n",
      "Full Dataset Precision:  0.9875389408099688\n",
      "Full Dataset Recall:  0.7270642201834863\n",
      "Full Dataset FScore:  0.8375165125495377\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Total Time taken:563.3733780384064\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_test=gen_df_encode\n",
    "df_test= prediction(df_test,'plot_lemm','Comedy',TfidfVectorizer, RandomForestClassifier(), {'n_estimators': [10,25,50,100],'max_depth':[100]})\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "\n",
    "print(\"Total Time taken:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre for prediction:  Adventure\n",
      "Number of 0s:  9516\n",
      "Number of 1s:  886\n",
      "Shape of the Sampled DataFrame:  (2658, 29)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[421  25]\n",
      " [130  89]]\n",
      "Sample data Test Set Precision:  0.7807017543859649\n",
      "Sample data Test Set Recall:  0.4063926940639269\n",
      "Sample data Test Set FScore:  0.5345345345345345\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[1326    0]\n",
      " [  12  655]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9820089955022488 0.9909228441754917\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9079  437]\n",
      " [ 142  744]]\n",
      "Full Dataset Precision:  0.6299745977984759\n",
      "Full Dataset Recall:  0.8397291196388262\n",
      "Full Dataset FScore:  0.7198838896952106\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Romance\n",
      "Number of 0s:  8728\n",
      "Number of 1s:  1674\n",
      "Shape of the Sampled DataFrame:  (5022, 30)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[790  41]\n",
      " [280 145]]\n",
      "Sample data Test Set Precision:  0.7795698924731183\n",
      "Sample data Test Set Recall:  0.3411764705882353\n",
      "Sample data Test Set FScore:  0.474631751227496\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[2517    0]\n",
      " [  39 1210]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9687750200160128 0.9841398942659617\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[8454  274]\n",
      " [ 319 1355]]\n",
      "Full Dataset Precision:  0.8317986494782075\n",
      "Full Dataset Recall:  0.8094384707287933\n",
      "Full Dataset FScore:  0.8204662428095671\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Horror\n",
      "Number of 0s:  9456\n",
      "Number of 1s:  946\n",
      "Shape of the Sampled DataFrame:  (2838, 31)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[449  27]\n",
      " [102 132]]\n",
      "Sample data Test Set Precision:  0.8301886792452831\n",
      "Sample data Test Set Recall:  0.5641025641025641\n",
      "Sample data Test Set FScore:  0.6717557251908397\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[1416    0]\n",
      " [   1  711]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9985955056179775 0.9992972593113141\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[8990  466]\n",
      " [ 103  843]]\n",
      "Full Dataset Precision:  0.6440030557677616\n",
      "Full Dataset Recall:  0.8911205073995772\n",
      "Full Dataset FScore:  0.7476718403547672\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Comedy\n",
      "Number of 0s:  6914\n",
      "Number of 1s:  3488\n",
      "Shape of the Sampled DataFrame:  (10402, 32)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[1671   44]\n",
      " [ 726  160]]\n",
      "Sample data Test Set Precision:  0.7843137254901961\n",
      "Sample data Test Set Recall:  0.18058690744920994\n",
      "Sample data Test Set FScore:  0.29357798165137616\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[5199    0]\n",
      " [ 243 2359]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9066102997694081 0.9510179399314654\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[6870   44]\n",
      " [ 969 2519]]\n",
      "Full Dataset Precision:  0.9828326180257511\n",
      "Full Dataset Recall:  0.7221903669724771\n",
      "Full Dataset FScore:  0.832589654602545\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Mystery\n",
      "Number of 0s:  9829\n",
      "Number of 1s:  573\n",
      "Shape of the Sampled DataFrame:  (1719, 33)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[268  22]\n",
      " [ 80  60]]\n",
      "Sample data Test Set Precision:  0.7317073170731707\n",
      "Sample data Test Set Recall:  0.42857142857142855\n",
      "Sample data Test Set FScore:  0.5405405405405405\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[856   0]\n",
      " [  2 431]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9953810623556582 0.9976851851851852\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9139  690]\n",
      " [  82  491]]\n",
      "Full Dataset Precision:  0.4157493649449619\n",
      "Full Dataset Recall:  0.8568935427574171\n",
      "Full Dataset FScore:  0.5598631698973774\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Action\n",
      "Number of 0s:  8933\n",
      "Number of 1s:  1469\n",
      "Shape of the Sampled DataFrame:  (4407, 34)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[696  45]\n",
      " [170 191]]\n",
      "Sample data Test Set Precision:  0.809322033898305\n",
      "Sample data Test Set Recall:  0.5290858725761773\n",
      "Sample data Test Set FScore:  0.6398659966499163\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[2197    0]\n",
      " [  19 1089]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9828519855595668 0.9913518434228493\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[8540  393]\n",
      " [ 189 1280]]\n",
      "Full Dataset Precision:  0.7650926479378363\n",
      "Full Dataset Recall:  0.8713410483321987\n",
      "Full Dataset FScore:  0.8147676639083387\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Film-Noir\n",
      "Number of 0s:  10374\n",
      "Number of 1s:  28\n",
      "Shape of the Sampled DataFrame:  (84, 35)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 2  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data Test Set Precision:  0.0\n",
      "Sample data Test Set Recall:  0.0\n",
      "Sample data Test Set FScore:  0.0\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[37  0]\n",
      " [ 0 26]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 1.0 1.0\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[10247   127]\n",
      " [    2    26]]\n",
      "Full Dataset Precision:  0.16993464052287582\n",
      "Full Dataset Recall:  0.9285714285714286\n",
      "Full Dataset FScore:  0.28729281767955805\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Thriller\n",
      "Number of 0s:  8336\n",
      "Number of 1s:  2066\n",
      "Shape of the Sampled DataFrame:  (6198, 36)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[988  60]\n",
      " [313 189]]\n",
      "Sample data Test Set Precision:  0.7590361445783133\n",
      "Sample data Test Set Recall:  0.37649402390438247\n",
      "Sample data Test Set FScore:  0.5033288948069241\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[3084    0]\n",
      " [  65 1499]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9584398976982097 0.9787789748612471\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[7968  368]\n",
      " [ 378 1688]]\n",
      "Full Dataset Precision:  0.8210116731517509\n",
      "Full Dataset Recall:  0.8170377541142304\n",
      "Full Dataset FScore:  0.819019893255701\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Drama\n",
      "Number of 0s:  5155\n",
      "Number of 1s:  5247\n",
      "Shape of the Sampled DataFrame:  (10402, 37)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[ 746  519]\n",
      " [ 307 1029]]\n",
      "Sample data Test Set Precision:  0.6647286821705426\n",
      "Sample data Test Set Recall:  0.7702095808383234\n",
      "Sample data Test Set FScore:  0.7135922330097086\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[3890    0]\n",
      " [  46 3865]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.988238302224495 0.9940843621399177\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[4636  519]\n",
      " [ 353 4894]]\n",
      "Full Dataset Precision:  0.9041197118049141\n",
      "Full Dataset Recall:  0.9327234610253479\n",
      "Full Dataset FScore:  0.9181988742964352\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  IMAX\n",
      "Number of 0s:  10231\n",
      "Number of 1s:  171\n",
      "Shape of the Sampled DataFrame:  (513, 38)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[80 10]\n",
      " [36  3]]\n",
      "Sample data Test Set Precision:  0.23076923076923078\n",
      "Sample data Test Set Recall:  0.07692307692307693\n",
      "Sample data Test Set FScore:  0.11538461538461538\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[252   0]\n",
      " [  6 126]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9545454545454546 0.9767441860465117\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9617  614]\n",
      " [  42  129]]\n",
      "Full Dataset Precision:  0.17362045760430686\n",
      "Full Dataset Recall:  0.7543859649122807\n",
      "Full Dataset FScore:  0.28227571115973743\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Fantasy\n",
      "Number of 0s:  9813\n",
      "Number of 1s:  589\n",
      "Shape of the Sampled DataFrame:  (1767, 39)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[286  20]\n",
      " [ 84  52]]\n",
      "Sample data Test Set Precision:  0.7222222222222222\n",
      "Sample data Test Set Recall:  0.38235294117647056\n",
      "Sample data Test Set FScore:  0.4999999999999999\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[872   0]\n",
      " [  4 449]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9911699779249448 0.9955654101995565\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9385  428]\n",
      " [  88  501]]\n",
      "Full Dataset Precision:  0.5392895586652314\n",
      "Full Dataset Recall:  0.8505942275042445\n",
      "Full Dataset FScore:  0.6600790513833993\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  War\n",
      "Number of 0s:  10100\n",
      "Number of 1s:  302\n",
      "Shape of the Sampled DataFrame:  (906, 40)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[144   7]\n",
      " [ 26  50]]\n",
      "Sample data Test Set Precision:  0.8771929824561403\n",
      "Sample data Test Set Recall:  0.6578947368421053\n",
      "Sample data Test Set FScore:  0.7518796992481203\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[453   0]\n",
      " [  0 226]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 1.0 1.0\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9665  435]\n",
      " [  26  276]]\n",
      "Full Dataset Precision:  0.3881856540084388\n",
      "Full Dataset Recall:  0.9139072847682119\n",
      "Full Dataset FScore:  0.5449160908193484\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Animation\n",
      "Number of 0s:  9998\n",
      "Number of 1s:  404\n",
      "Shape of the Sampled DataFrame:  (1212, 41)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[186  14]\n",
      " [ 75  28]]\n",
      "Sample data Test Set Precision:  0.6666666666666666\n",
      "Sample data Test Set Recall:  0.27184466019417475\n",
      "Sample data Test Set FScore:  0.38620689655172413\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[608   0]\n",
      " [  2 299]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9933554817275747 0.9966666666666666\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9601  397]\n",
      " [  77  327]]\n",
      "Full Dataset Precision:  0.4516574585635359\n",
      "Full Dataset Recall:  0.8094059405940595\n",
      "Full Dataset FScore:  0.5797872340425532\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Crime\n",
      "Number of 0s:  9176\n",
      "Number of 1s:  1226\n",
      "Shape of the Sampled DataFrame:  (3678, 42)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[554  42]\n",
      " [120 204]]\n",
      "Sample data Test Set Precision:  0.8292682926829268\n",
      "Sample data Test Set Recall:  0.6296296296296297\n",
      "Sample data Test Set FScore:  0.7157894736842105\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[1856    0]\n",
      " [  13  889]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9855875831485588 0.9927414852037968\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[8528  648]\n",
      " [ 133 1093]]\n",
      "Full Dataset Precision:  0.6278001148765078\n",
      "Full Dataset Recall:  0.8915171288743883\n",
      "Full Dataset FScore:  0.7367711493090665\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Western\n",
      "Number of 0s:  10305\n",
      "Number of 1s:  97\n",
      "Shape of the Sampled DataFrame:  (291, 43)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[45  7]\n",
      " [12  9]]\n",
      "Sample data Test Set Precision:  0.5625\n",
      "Sample data Test Set Recall:  0.42857142857142855\n",
      "Sample data Test Set FScore:  0.4864864864864864\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[142   0]\n",
      " [  1  75]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9868421052631579 0.9933774834437086\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9582  723]\n",
      " [  13   84]]\n",
      "Full Dataset Precision:  0.10408921933085502\n",
      "Full Dataset Recall:  0.865979381443299\n",
      "Full Dataset FScore:  0.18584070796460178\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Sci-Fi\n",
      "Number of 0s:  9754\n",
      "Number of 1s:  648\n",
      "Shape of the Sampled DataFrame:  (1944, 44)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[309  16]\n",
      " [ 61 100]]\n",
      "Sample data Test Set Precision:  0.8620689655172413\n",
      "Sample data Test Set Recall:  0.6211180124223602\n",
      "Sample data Test Set FScore:  0.7220216606498194\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[971   0]\n",
      " [  2 485]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9958932238193019 0.9979423868312758\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9345  409]\n",
      " [  63  585]]\n",
      "Full Dataset Precision:  0.5885311871227364\n",
      "Full Dataset Recall:  0.9027777777777778\n",
      "Full Dataset FScore:  0.7125456760048722\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Musical\n",
      "Number of 0s:  10118\n",
      "Number of 1s:  284\n",
      "Shape of the Sampled DataFrame:  (852, 45)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[137   3]\n",
      " [ 43  30]]\n",
      "Sample data Test Set Precision:  0.9090909090909091\n",
      "Sample data Test Set Recall:  0.410958904109589\n",
      "Sample data Test Set FScore:  0.5660377358490566\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[428   0]\n",
      " [  4 207]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.981042654028436 0.9904306220095694\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9689  429]\n",
      " [  47  237]]\n",
      "Full Dataset Precision:  0.35585585585585583\n",
      "Full Dataset Recall:  0.8345070422535211\n",
      "Full Dataset FScore:  0.4989473684210526\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Children\n",
      "Number of 0s:  9884\n",
      "Number of 1s:  518\n",
      "Shape of the Sampled DataFrame:  (1554, 46)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[257  12]\n",
      " [ 59  61]]\n",
      "Sample data Test Set Precision:  0.8356164383561644\n",
      "Sample data Test Set Recall:  0.5083333333333333\n",
      "Sample data Test Set FScore:  0.6321243523316062\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[767   0]\n",
      " [  1 397]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 1.0 0.9974874371859297 0.9987421383647799\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9378  506]\n",
      " [  60  458]]\n",
      "Full Dataset Precision:  0.475103734439834\n",
      "Full Dataset Recall:  0.8841698841698842\n",
      "Full Dataset FScore:  0.6180836707152497\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n",
      "Genre for prediction:  Documentary\n",
      "Number of 0s:  9342\n",
      "Number of 1s:  1060\n",
      "Shape of the Sampled DataFrame:  (3180, 47)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n",
      "Model Building End\n",
      "\n",
      "\n",
      "Sample data Test Set Confusion Matrix: \n",
      "[[502  16]\n",
      " [100 177]]\n",
      "Sample data Test Set Precision:  0.917098445595855\n",
      "Sample data Test Set Recall:  0.6389891696750902\n",
      "Sample data Test Set FScore:  0.7531914893617021\n",
      "\n",
      "\n",
      "Sample data Train Set Confusion Matrix: \n",
      "[[1600    2]\n",
      " [   7  776]]\n",
      "Sample data Train Set (Precision, Recall, Fscore) : 0.9974293059125964 0.9910600255427842 0.994234465086483\n",
      "\n",
      "\n",
      "Probability Evaluation and Concat Start\n",
      "Probability Evaluation and Concat End\n",
      "\n",
      "\n",
      "Full Dataset Confusion Matrix  RandomForestClassifier()\n",
      "[[9059  283]\n",
      " [ 107  953]]\n",
      "Full Dataset Precision:  0.7710355987055016\n",
      "Full Dataset Recall:  0.8990566037735849\n",
      "Full Dataset FScore:  0.8301393728222998\n",
      "\n",
      "\n",
      "Appending results to Final_data Start\n",
      "Appending results to Final_data End\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "to_pickle() got an unexpected keyword argument 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-01fee39b2598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mg_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf_test\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'plot_lemm'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\RF_Probability_Distribution_plots.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: to_pickle() got an unexpected keyword argument 'index'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_test=gen_df_encode\n",
    "for i in g_list:    \n",
    "    df_test= prediction(df_test,'plot_lemm',i,TfidfVectorizer, RandomForestClassifier(), {'n_estimators': [10,25,50,100],'max_depth':[100]})\n",
    "df_test.to_pickle(r'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\RF_Probability_Distribution_plots.pkl',index=False)\n",
    "total_time = end-start\n",
    "\n",
    "print(\"Total Time taken:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_pickle(r'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\RF_Probability_Distribution_plots.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre for prediction:  Comedy\n",
      "Number of 0s:  6914\n",
      "Number of 1s:  3488\n",
      "Shape of the Sampled DataFrame:  (10402, 29)\n",
      "\n",
      "\n",
      "Vectorization Start\n",
      "Vectorization End\n",
      "\n",
      "\n",
      "Model Building Start\n"
     ]
    }
   ],
   "source": [
    "df_test=gen_df_encode\n",
    "for i in g_list:    \n",
    "    df_test = prediction(df_test,'plot_lemm',i,TfidfVectorizer, svm.SVC(probability=True),  {'kernel': ['linear','rbf']})\n",
    "df_test.to_pickle(r'D:\\Machine Learning\\Vamsi Thesis\\Code\\Results\\SVM_Probability_Distribution_plots.pkl',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
